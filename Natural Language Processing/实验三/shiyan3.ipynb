{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c279a54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hanlp\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2206df2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    }
   ],
   "source": [
    "HanLP = hanlp.load(hanlp.pretrained.mtl.CLOSE_TOK_POS_NER_SRL_DEP_SDP_CON_ELECTRA_SMALL_ZH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6969c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分词后的结果:  [['阿婆主', '来到', '北京', '立方庭', '参观', '自然', '语义', '科技', '公司', '。']]\n",
      "词性分析结果:  [['n', 'v', 'ns', 'ns', 'v', 'n', 'n', 'n', 'n', 'w']]\n",
      "依存句法分析结果:  [[(1, 'nsubj'), (-1, 'root'), (3, 'nn'), (1, 'dobj'), (1, 'conj'), (6, 'nn'), (8, 'nn'), (8, 'nn'), (4, 'dobj'), (1, 'punct')]]\n"
     ]
    }
   ],
   "source": [
    "def process_dep(dep_list):\n",
    "    new_dep_list = []\n",
    "    for dep_sent in dep_list:\n",
    "        new_dep_list.append([(tup[0] - 1, tup[1]) for tup in dep_sent])\n",
    "    return new_dep_list\n",
    "\n",
    "target_sentence = \"阿婆主来到北京立方庭参观自然语义科技公司。\"\n",
    "target_results = HanLP([target_sentence])\n",
    "\n",
    "print('分词后的结果: ', target_results[\"tok/fine\"])\n",
    "print('词性分析结果: ', target_results[\"pos/pku\"])\n",
    "print('依存句法分析结果: ', process_dep(target_results[\"dep\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d2af7033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(1, 'nsubj'), (-1, 'root'), (3, 'nn'), (1, 'dobj'), (1, 'conj'), (6, 'nn'), (8, 'nn'), (8, 'nn'), (4, 'dobj'), (1, 'punct')]]\n",
      "['阿婆主', '来到', '北京', '立方庭', '参观', '自然', '语义', '科技', '公司', '。']\n",
      "0 *** 1 *** nsubj\n",
      "阿婆主\n",
      "******************************\n",
      "1 *** -1 *** root\n",
      "来到\n",
      "******************************\n",
      "2 *** 3 *** nn\n",
      "北京\n",
      "******************************\n",
      "3 *** 1 *** dobj\n",
      "立方庭\n",
      "******************************\n",
      "4 *** 1 *** conj\n",
      "参观\n",
      "******************************\n",
      "5 *** 6 *** nn\n",
      "自然\n",
      "******************************\n",
      "6 *** 8 *** nn\n",
      "语义\n",
      "******************************\n",
      "7 *** 8 *** nn\n",
      "科技\n",
      "******************************\n",
      "8 *** 4 *** dobj\n",
      "公司\n",
      "******************************\n",
      "9 *** 1 *** punct\n",
      "。\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "dependency_result = process_dep(target_results[\"dep\"])\n",
    "segmented_result = target_results[\"tok/fine\"]\n",
    "segmented_result = segmented_result[0]\n",
    "print(dependency_result)\n",
    "print(segmented_result)\n",
    "for word_idx, (parent_idx, relation_type) in enumerate(dependency_result[0]):\n",
    "    print(word_idx,'***',parent_idx,'***',relation_type)\n",
    "    print(segmented_result[word_idx])\n",
    "    print('*'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "857d87cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "阿婆主 的父节点是 来到，边的类型是 nsubj\n",
      "来到 是 根节点\n",
      "北京 的父节点是 立方庭，边的类型是 nn\n",
      "立方庭 的父节点是 来到，边的类型是 dobj\n",
      "参观 的父节点是 来到，边的类型是 conj\n",
      "自然 的父节点是 语义，边的类型是 nn\n",
      "语义 的父节点是 公司，边的类型是 nn\n",
      "科技 的父节点是 公司，边的类型是 nn\n",
      "公司 的父节点是 参观，边的类型是 dobj\n",
      "。 的父节点是 来到，边的类型是 punct\n"
     ]
    }
   ],
   "source": [
    "for word_idx, (parent_idx, relation_type) in enumerate(dependency_result[0]):\n",
    "    word = segmented_result[word_idx]\n",
    "    if parent_idx == -1:\n",
    "        print(f\"{word} 是 根节点\")\n",
    "    else:\n",
    "        parent_word = segmented_result[parent_idx]\n",
    "        print(f\"{word} 的父节点是 {parent_word}，边的类型是 {relation_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "009d84fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 'nsubj', 1), (1, 'root', -1), (2, 'nn', 3), (3, 'dobj', 1), (4, 'conj', 1), (5, 'nn', 6), (6, 'nn', 8), (7, 'nn', 8), (8, 'dobj', 4), (9, 'punct', 1)]]\n",
      "['阿婆主', '来到', '北京', '立方庭', '参观', '自然', '语义', '科技', '公司', '。']\n"
     ]
    }
   ],
   "source": [
    "new_dependency_result = []\n",
    "for word_idx, (parent_idx, relation_type) in enumerate(dependency_result[0]):\n",
    "    new_dependency_result.append((word_idx, relation_type, parent_idx))\n",
    "new_dependency_result = [new_dependency_result]\n",
    "\n",
    "print(new_dependency_result)\n",
    "print(segmented_result)\n",
    "# for word_idx, relation_type, parent_idx in new_dependency_result:\n",
    "#     print(word_idx,\"***\",relation_type,\"***\",parent_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "12954375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_aspect_and_sentiment(dependency_result, segmented_result):\n",
    "    aspect_words = []\n",
    "    sentiment_words = []\n",
    "    word_index_dict = {i: word for i, word in enumerate(segmented_result)}\n",
    "    neg_positions = list()\n",
    "    degree_positions = list()\n",
    "    average_neg = list()\n",
    "    average_word = list()\n",
    "    # ⑨\n",
    "    for word_idx, relation_type, parent_idx in dependency_result:\n",
    "        if relation_type == \"neg\":\n",
    "            neg_positions.append(word_idx)\n",
    "            average_neg.append(parent_idx)\n",
    "            average_word.append(word_index_dict.get(word_idx, \"\"))\n",
    "        elif relation_type == \"advmod\":\n",
    "            degree_positions.append(word_idx)\n",
    "    \n",
    "    for word_idx, relation_type, parent_idx in dependency_result:\n",
    "        word = word_index_dict.get(word_idx, \"\")\n",
    "        parent_word = word_index_dict.get(parent_idx, \"\")\n",
    "        # ①\n",
    "        if relation_type == \"nsubj\":\n",
    "            aspect_words.append(word)\n",
    "        # ②\n",
    "        elif relation_type == \"dobj\":\n",
    "            aspect_words.append(word)\n",
    "        # ③\n",
    "        elif relation_type == \"nmod:topic\" or relation_type == \"top\":\n",
    "            aspect_words.append(word)\n",
    "        # ④\n",
    "        elif relation_type == \"amod\":\n",
    "            sentiment = word\n",
    "            if is_emotional_adjective(word):\n",
    "                if word_idx in average_neg:\n",
    "                    sentiment = average_word[average_neg.index(word_idx)] + sentiment\n",
    "                for deg_idx, deg_type, deg_parent in dependency_result:\n",
    "                    if deg_type == \"advmod\" and deg_parent == word_idx:\n",
    "                        degree_word = word_index_dict.get(deg_idx, \"\")\n",
    "                        sentiment = degree_word + sentiment\n",
    "            sentiment_words.append(sentiment)\n",
    "        # ⑤\n",
    "        elif relation_type == \"advmod\":\n",
    "            adv_word = word\n",
    "            modified_word = parent_word\n",
    "            if parent_idx in average_neg:\n",
    "                sentiment_words.append(adv_word)\n",
    "            elif is_emotional_adjective(modified_word):\n",
    "                sentiment_words.append(adv_word)\n",
    "                sentiment_words.append(modified_word)\n",
    "            else:\n",
    "                for other_idx, other_type, other_parent in dependency_result:\n",
    "                    if other_parent == parent_idx and other_type == \"amod\":\n",
    "                        adj_word = word_index_dict.get(other_idx, \"\")\n",
    "                        if is_emotional_adjective(adj_word):\n",
    "                            sentiment_words.append(adv_word)\n",
    "                            sentiment_words.append(adj_word)\n",
    "        # ⑥\n",
    "        elif relation_type == \"conj\" or relation_type == \"dep\":\n",
    "            adj1 = parent_word\n",
    "            adj2 = word\n",
    "            if is_emotional_adjective(adj1) and is_emotional_adjective(adj2):\n",
    "                sentiment_words.append(adj2)\n",
    "                sentiment_words.append(adj1)\n",
    "        # ⑦\n",
    "        elif relation_type == \"xcomp\":\n",
    "            if is_emotional_adjective(word):\n",
    "                for subj_idx, subj_type, subj_parent in dependency_result:\n",
    "                    if subj_type == \"nsubj\" and subj_parent == parent_idx:\n",
    "                        aspect_word = word_index_dict.get(subj_idx, \"\")\n",
    "                        aspect_words.append(aspect_word)\n",
    "                sentiment_words.append(word)\n",
    "        # ⑧\n",
    "        elif relation_type == \"ccomp\":\n",
    "            if is_emotional_adjective(word):\n",
    "                for subj_idx, subj_type, subj_parent in dependency_result:\n",
    "                    if subj_type == \"nsubj\" and subj_parent == word_idx:\n",
    "                        aspect_words.append(word_index_dict.get(subj_idx, \"\"))\n",
    "                sentiment_words.append(word)\n",
    "        # 补充，根节点\n",
    "        elif relation_type == \"root\" and is_emotional_word(word):\n",
    "            if word_idx in average_neg:\n",
    "                    word = average_word[average_neg.index(word_idx)] + word\n",
    "            sentiment_words.append(word)\n",
    "        # ⑩\n",
    "        elif is_emotional_verb(word):\n",
    "            sentiment_words.append(word)\n",
    "            for other_idx, other_type, other_parent in dependency_result:\n",
    "                if other_parent == word_idx:\n",
    "                    if other_type == \"nsubj\" or other_type == \"dobj\":\n",
    "                        aspect_words.append(word_index_dict.get(other_idx, \"\"))\n",
    "        \n",
    "    return aspect_words, sentiment_words\n",
    "# ⑩\n",
    "def is_emotional_adjective(word):\n",
    "    emotional_adjectives = {\n",
    "        \"好\", \"坏\", \"优秀\", \"糟糕\", \"完美\", \"差\", \"舒适\", \"难受\", \"干净\", \"脏\", \n",
    "        \"漂亮\", \"丑\", \"美丽\", \"难看\", \"满意\", \"不满\", \"热情\", \"冷淡\", \"细致\",\n",
    "        \"粗糙\", \"便宜\", \"贵\", \"合适\", \"不当\", \"新鲜\", \"陈旧\", \"高效\", \"低效\",\n",
    "        \"强大\", \"弱小\", \"宽敞\", \"狭窄\", \"明亮\", \"昏暗\", \"温馨\", \"冷清\"\n",
    "    }\n",
    "    return word in emotional_adjectives\n",
    "# ⑩\n",
    "def is_emotional_verb(word):\n",
    "    emotional_verbs = {\n",
    "        \"喜欢\", \"讨厌\", \"满意\", \"不满\", \"称赞\", \"批评\", \"赞同\", \"反对\", \n",
    "        \"欣赏\", \"厌恶\", \"推荐\", \"反对\", \"认可\", \"质疑\", \"表扬\", \"责备\"\n",
    "    }\n",
    "    return word in emotional_verbs\n",
    "# ⑩\n",
    "def is_emotional_word(word):\n",
    "    return is_emotional_adjective(word) or is_emotional_verb(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "da980a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分词后的结果:  ['你', '像', '公主', '一样', '美丽']\n",
      "依存句法分析结果:  [[(3, 'nsubj'), (3, 'prep'), (1, 'pobj'), (-1, 'root'), (3, 'dep')]]\n"
     ]
    }
   ],
   "source": [
    "target_sentence = \"你像公主一样美丽\"\n",
    "target_results = HanLP([target_sentence])\n",
    "dependency_result = process_dep(target_results[\"dep\"])\n",
    "segmented_result = target_results[\"tok/fine\"]\n",
    "segmented_result = segmented_result[0]\n",
    "print('分词后的结果: ', segmented_result)\n",
    "print('依存句法分析结果: ', dependency_result)\n",
    "\n",
    "new_dependency_result = []\n",
    "for word_idx, (parent_idx, relation_type) in enumerate(dependency_result[0]):\n",
    "    new_dependency_result.append((word_idx, relation_type, parent_idx))\n",
    "#     print(word_idx,\"***\",relation_type,\"***\",parent_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "9f3bb9fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "方面词: ['你']\n",
      "情感词: []\n"
     ]
    }
   ],
   "source": [
    "aspect_words, sentiment_words = extract_aspect_and_sentiment(new_dependency_result, segmented_result)\n",
    "aspect_words = list(set(aspect_words))\n",
    "sentiment_words = list(set(sentiment_words))\n",
    "print(\"方面词:\", aspect_words)\n",
    "print(\"情感词:\", sentiment_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f9e02ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1200 entries, 0 to 1199\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   1200 non-null   int64 \n",
      " 1   text_a  1200 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 18.9+ KB\n",
      "這間酒店環境和服務態度亦算不錯,但房間空間太小~~不宣容納太大件行李~~且房間格調還可以~~ 中餐廳的廣東點心不太好吃~~要改善之~~~~但算價錢平宜~~可接受~~ 西餐廳格調都很好~~但吃的味道一般且令人等得太耐了~~要改善之~~\n",
      "Segmented Beginning\n",
      "Pos Beginning\n",
      "Dependency Beginning\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\86178\\Desktop\\shiyan3\\sentiment.tsv', sep='\\t')\n",
    "data.info()\n",
    "print(data['text_a'][0])\n",
    "\n",
    "print('Segmented Beginning')\n",
    "data['segmented_text'] = data['text_a'].apply(lambda x: HanLP([x])[\"tok/fine\"])\n",
    "print('Pos Beginning')\n",
    "data['pos_result'] = data['text_a'].apply(lambda x: HanLP([x])[\"pos/pku\"])\n",
    "print('Dependency Beginning')\n",
    "data['dependency_result'] = data['text_a'].apply(lambda x: process_dep(HanLP([x])[\"dep\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c5ed6f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_csv_path = r'C:\\Users\\86178\\Desktop\\shiyan3\\new_sentiment.csv'\n",
    "data.to_csv(new_csv_path, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "b05fabf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_aspect_and_sentiment(dependency_result, segmented_result):\n",
    "    aspect_words = []\n",
    "    sentiment_words = []\n",
    "    word_index_dict = {i: word for i, word in enumerate(segmented_result)}\n",
    "    \n",
    "    # 存储否定词和程度副词信息\n",
    "    neg_positions = list()\n",
    "    degree_positions = list()\n",
    "    average_neg = list()\n",
    "    average_word = list()\n",
    "    \n",
    "    # 存储比喻关系\n",
    "    simile_pairs = []  # 存储比喻关系的词对\n",
    "    \n",
    "    # 第一遍扫描：收集修饰词和比喻关系\n",
    "    for word_idx, relation_type, parent_idx in dependency_result:\n",
    "        word = word_index_dict.get(word_idx, \"\")\n",
    "        parent_word = word_index_dict.get(parent_idx, \"\")\n",
    "        \n",
    "        if relation_type == \"neg\":\n",
    "            neg_positions.append(word_idx)\n",
    "            average_neg.append(parent_idx)\n",
    "            average_word.append(word)\n",
    "        elif relation_type == \"advmod\":\n",
    "            degree_positions.append(word_idx)\n",
    "        # 处理比喻关系\n",
    "        elif is_simile_word(word):  # 检查是否是比喻词（如\"像\"、\"似\"等）\n",
    "            # 查找比喻词前后的名词和形容词\n",
    "            for other_idx, other_type, other_parent in dependency_result:\n",
    "                if other_parent == word_idx or other_parent == parent_idx:\n",
    "                    simile_pairs.append((word_idx, other_idx))\n",
    "    \n",
    "    # 第二遍扫描：提取方面词和情感词\n",
    "    for word_idx, relation_type, parent_idx in dependency_result:\n",
    "        word = word_index_dict.get(word_idx, \"\")\n",
    "        parent_word = word_index_dict.get(parent_idx, \"\")\n",
    "        \n",
    "        # 处理比喻句中的情感词\n",
    "        if is_emotional_adjective(word):\n",
    "            sentiment = word\n",
    "            # 检查是否在比喻结构中\n",
    "            for simile_start, simile_end in simile_pairs:\n",
    "                if word_idx >= simile_start and word_idx <= simile_end:\n",
    "                    # 处理否定词\n",
    "                    if word_idx in average_neg:\n",
    "                        sentiment = average_word[average_neg.index(word_idx)] + sentiment\n",
    "                    # 处理程度副词\n",
    "                    for deg_idx, deg_type, deg_parent in dependency_result:\n",
    "                        if deg_type == \"advmod\" and deg_parent == word_idx:\n",
    "                            degree_word = word_index_dict.get(deg_idx, \"\")\n",
    "                            if is_degree_word(degree_word):\n",
    "                                sentiment = degree_word + sentiment\n",
    "                    sentiment_words.append(sentiment)\n",
    "                    break\n",
    "        \n",
    "        # 处理主语（可能是比喻的对象）\n",
    "        elif relation_type == \"nsubj\":\n",
    "            if not is_stop_word(word):\n",
    "                aspect_words.append(word)\n",
    "                # 查找与主语相关的情感词\n",
    "                for other_idx, other_type, other_parent in dependency_result:\n",
    "                    if other_parent == parent_idx and is_emotional_adjective(word_index_dict.get(other_idx, \"\")):\n",
    "                        sentiment_words.append(word_index_dict.get(other_idx, \"\"))\n",
    "        \n",
    "        # 其他原有的处理逻辑保持不变...\n",
    "        \n",
    "    return aspect_words, sentiment_words\n",
    "\n",
    "def is_simile_word(word):\n",
    "    \"\"\"判断是否是比喻词\"\"\"\n",
    "    simile_words = {\"像\", \"似\", \"如\", \"若\", \"仿佛\", \"好比\", \"宛如\", \"恰似\", \"犹如\"}\n",
    "    return word in simile_words\n",
    "\n",
    "def is_degree_word(word):\n",
    "    \"\"\"判断是否是程度副词\"\"\"\n",
    "    degree_words = {\n",
    "        \"很\", \"非常\", \"特别\", \"格外\", \"分外\", \"十分\", \"极其\", \"极度\",\n",
    "        \"极端\", \"极为\", \"最为\", \"最\", \"太\", \"更\", \"更加\", \"格外\",\n",
    "        \"一样\", \"那样\", \"这样\", \"如此\"  # 添加比喻相关的程度词\n",
    "    }\n",
    "    return word in degree_words\n",
    "\n",
    "def is_emotional_adjective(word):\n",
    "    \"\"\"判断是否是情感形容词\"\"\"\n",
    "    emotional_adjectives = {\n",
    "        # 原有的情感词\n",
    "        \"好\", \"坏\", \"优秀\", \"糟糕\", \"完美\", \"差\", \"舒适\", \"难受\", \"干净\", \"脏\", \n",
    "        \"漂亮\", \"丑\", \"美丽\", \"难看\", \"满意\", \"不满\", \"热情\", \"冷淡\", \"细致\",\n",
    "        \"粗糙\", \"便宜\", \"贵\", \"合适\", \"不当\", \"新鲜\", \"陈旧\", \"高效\", \"低效\",\n",
    "        \"强大\", \"弱小\", \"宽敞\", \"狭窄\", \"明亮\", \"昏暗\", \"温馨\", \"冷清\",\n",
    "        # 添加形容外表和性格的词\n",
    "        \"美\", \"丑\", \"漂亮\", \"英俊\", \"帅\", \"美丽\", \"可爱\", \"迷人\", \"优雅\",\n",
    "        \"高贵\", \"典雅\", \"端庄\", \"秀丽\", \"清秀\", \"俊俏\", \"标致\"\n",
    "    }\n",
    "    return word in emotional_adjectives\n",
    "\n",
    "def is_stop_word(word):\n",
    "    \"\"\"判断是否是停用词\"\"\"\n",
    "    stop_words = {\n",
    "        \"的\", \"了\", \"着\", \"来\", \"去\", \"到\", \"在\", \"和\", \"与\", \"及\",\n",
    "        \"或\", \"而\", \"但\", \"却\", \"且\", \"被\", \"把\", \"将\", \"向\", \"往\",\n",
    "        \"是\", \"有\", \"没\", \"不\", \"这\", \"那\", \"这个\", \"那个\", \"之\",\n",
    "        \"都\", \"也\", \"还\", \"又\", \"就\", \"很\", \"比较\", \"更\", \"最\"\n",
    "    }\n",
    "    return word in stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "b37340c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分词后的结果:  ['你', '像', '公主', '一样', '美丽']\n",
      "依存句法分析结果:  [[(3, 'nsubj'), (3, 'prep'), (1, 'pobj'), (-1, 'root'), (3, 'dep')]]\n",
      "方面词: ['你']\n",
      "情感词: ['美丽']\n"
     ]
    }
   ],
   "source": [
    "target_sentence = \"你像公主一样美丽\"\n",
    "target_results = HanLP([target_sentence])\n",
    "dependency_result = process_dep(target_results[\"dep\"])\n",
    "segmented_result = target_results[\"tok/fine\"]\n",
    "segmented_result = segmented_result[0]\n",
    "print('分词后的结果: ', segmented_result)\n",
    "print('依存句法分析结果: ', dependency_result)\n",
    "\n",
    "new_dependency_result = []\n",
    "for word_idx, (parent_idx, relation_type) in enumerate(dependency_result[0]):\n",
    "    new_dependency_result.append((word_idx, relation_type, parent_idx))\n",
    "#     print(word_idx,\"***\",relation_type,\"***\",parent_idx)\n",
    "aspect_words, sentiment_words = extract_aspect_and_sentiment(new_dependency_result, segmented_result)\n",
    "aspect_words = list(set(aspect_words))\n",
    "sentiment_words = list(set(sentiment_words))\n",
    "print(\"方面词:\", aspect_words)\n",
    "print(\"情感词:\", sentiment_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "aeb388e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 1 个句子:\n",
      "方面词: []\n",
      "情感词: ['可以', '很好', '一般']\n",
      "------------------------------\n",
      "第 2 个句子:\n",
      "方面词: []\n",
      "情感词: ['推荐']\n",
      "------------------------------\n",
      "第 3 个句子:\n",
      "方面词: ['速度']\n",
      "情感词: []\n",
      "------------------------------\n",
      "第 4 个句子:\n",
      "方面词: []\n",
      "情感词: ['很满意', '简单']\n",
      "------------------------------\n",
      "第 5 个句子:\n",
      "方面词: ['电池', '系统']\n",
      "情感词: ['可以']\n",
      "------------------------------\n",
      "第 6 个句子:\n",
      "方面词: []\n",
      "情感词: ['一般']\n",
      "------------------------------\n",
      "第 7 个句子:\n",
      "方面词: []\n",
      "情感词: []\n",
      "------------------------------\n",
      "第 8 个句子:\n",
      "方面词: ['性能']\n",
      "情感词: ['喜欢', '十分好', '不错']\n",
      "------------------------------\n",
      "第 9 个句子:\n",
      "方面词: ['驱动', '键盘', '显卡', 'N卡']\n",
      "情感词: ['偏向', '很容易', '足够强大']\n",
      "------------------------------\n",
      "第 10 个句子:\n",
      "方面词: []\n",
      "情感词: ['很喜欢', '不错']\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for index in range(10):\n",
    "    print(f\"第 {index + 1} 个句子:\")\n",
    "    segmented_result = data['segmented_text'].iloc[index][0]\n",
    "    dependency_result = data['dependency_result'].iloc[index]\n",
    "    new_dependency_result = []\n",
    "    for word_idx, (parent_idx, relation_type) in enumerate(dependency_result[0]):\n",
    "        new_dependency_result.append((word_idx, relation_type, parent_idx))\n",
    "\n",
    "    aspect_words, sentiment_words = extract_aspect_and_sentiment(new_dependency_result, segmented_result)\n",
    "    aspect_words = list(set(aspect_words))\n",
    "    sentiment_words = list(set(sentiment_words))\n",
    "\n",
    "    print(\"方面词:\", aspect_words)\n",
    "    print(\"情感词:\", sentiment_words)\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27c5cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
